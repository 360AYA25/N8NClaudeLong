# ğŸ¯ Universal Solution Patterns

> **FOR BOTS: How to Read This File**
>
> Use **Grep + Read with offset/limit** to find relevant patterns:
>
> ```javascript
> // Find pattern by keyword
> Grep: {pattern: "Incremental", "-n": true, output_mode: "content"}
> // Result: "7:## Pattern 0: ğŸš€ Incremental n8n Workflow Creation"
>
> // Read that pattern
> Read: {file_path: "PATTERNS.md", offset: 7, limit: 150}
> ```

> **FOR BOTS: How to Write to This File**
>
> 1. **Determine section:** âœ… Proven Patterns OR âŒ Anti-Patterns
> 2. **Find similar pattern** with Grep to avoid duplicates
> 3. **Add new pattern** in relevant section (chronological order, newest on top)
> 4. **Use format:**
>    - **Proven Patterns:** When to use â†’ Problem â†’ Solution â†’ Code Template â†’ Critical Rules â†’ Examples
>    - **Anti-Patterns:** What NOT to do â†’ Why it's bad â†’ Use instead â†’ Example

---

## âš¡ QUICK REFERENCE - Critical Patterns (Always Check First!)

**For Architect agents: Check these BEFORE generating plans!**

### ğŸ”´ Set Node v3.4+ (CRITICAL!)
```javascript
// âŒ WRONG - Missing ={{ prefix
"value": "string{{ $json.field }}"

// âœ… CORRECT - With ={{ prefix
"value": "={{ 'string' + $json.field }}"

// Required fields:
{
  "mode": "manual",                    // MANDATORY v3.4+
  "assignments": {
    "assignments": [                   // Array, not object!
      {
        "id": "unique-id",
        "name": "output_field",
        "type": "string|number|boolean",
        "value": "={{ ... }}"          // Start with ={{
      }
    ]
  }
}
```

### ğŸŸ¡ IF Node v2+ (Common Issue)
```javascript
// âŒ WRONG - conditions as object
"conditions": {
  "leftValue": "...",
  "operation": "equals",
  "rightValue": "..."
}

// âœ… CORRECT - conditions as ARRAY
"conditions": {
  "conditions": [              // Wrap in array!
    {
      "leftValue": "={{ $statusCode }}",
      "operation": "equals",
      "rightValue": 200
    }
  ]
}
```

### ğŸŸ  HTTP Request v4.2+ (Known Bug)
```javascript
// âŒ WRONG - ignoreHttpStatusErrors doesn't work
"parameters": {
  "options": {
    "ignoreHttpStatusErrors": true   // IGNORED in v4.2!
  }
}

// âœ… CORRECT - Use continueOnFail at node level
"continueOnFail": true,              // Node level, not parameters!
"parameters": {
  "url": "...",
  "method": "GET"
}
```

### ğŸŸ¢ Pattern 47: Never Trust Defaults (Universal)
```javascript
// ALWAYS specify:
"typeVersion": 3.4,        // Explicit version
"method": "GET",           // Don't trust default
"mode": "manual",          // Set node requirement
"sendHeaders": true,       // HTTP Request explicit
"responseFormat": "json"   // HTTP Request explicit
```

### ğŸŸ£ Pattern 15: Cascading Parameter Changes (CRITICAL for Debugging!)
```javascript
// BEFORE changing any parameter - ALWAYS check downstream impact!

// âŒ WRONG - Changed one node only
// Set node: renamed "user_id" â†’ "userId"
// Result: 5 downstream nodes broke (Code, IF, Supabase)

// âœ… CORRECT - Pre-Change Checklist
// Step 1: Search for all references
grep -n "user_id" workflow.json
// Found: Code node (3 refs), IF node (1 ref), Supabase (1 ref)

// Step 2: Update ALL nodes simultaneously
// - Set node: "userId"
// - Code node: $json.userId (3 places)
// - IF node: {{ $json.userId }}
// - Supabase: fieldValue: "={{ $json.userId }}"

// Step 3: Test end-to-end
// All 6 nodes working âœ…

// CRITICAL RULE: One parameter change = Multiple node updates
// Never change in isolation!
```

### ğŸ”µ Connection Syntax (4-param format)
```javascript
// âœ… CORRECT - 4 parameters
"connections": {
  "Node A": {
    "main": [[
      {
        "node": "Node B",    // Target node name
        "type": "main",      // Connection type
        "index": 0           // Output port index
      }
    ]]
  }
}

// IF node branches:
"IF Node": {
  "main": [
    [{"node": "Success", "type": "main", "index": 0}],  // Branch 0 (TRUE)
    [{"node": "Error", "type": "main", "index": 0}]     // Branch 1 (FALSE)
  ]
}
```

**Reference:** See Pattern 0, Pattern 15, LEARNINGS.md entry [2025-11-12 23:00], [2025-11-18 16:00], architect.md pre-validation

---

## ğŸ“‘ Quick Index

| Pattern | Line | Topic |
|---------|------|-------|
| [Pattern 0: Incremental Workflow Creation](#pattern-0--incremental-n8n-workflow-creation-via-mcp-critical) | 50 | n8n MCP step-by-step |
| [Pattern 0.5: Modifying Nodes](#pattern-05--modifying-individual-nodes-in-n8n-workflows-via-mcp) | 185 | n8n MCP remove+add |
| [Pattern 1-14](#pattern-1-dynamic-database-selection-n8n--notion) | 410 | Various n8n patterns |
| [Pattern 15: Cascading Parameter Changes](#pattern-15--cascading-parameter-changes-critical-for-debugging--building) | 970 | Critical for debugging & building |
| [Anti-Patterns](#-anti-patterns-what-not-to-do) | 1290 | Common mistakes to avoid |

---

## Pattern 0: ğŸš€ Smart n8n Workflow Creation Strategy (CRITICAL!)

**When to use:**
- Creating n8n workflows programmatically via n8n-MCP
- Any workflow size (3-50+ nodes)
- Optimizing token consumption

**Problem:**
- **Per-node incremental:** 8 nodes = ~2000 tokens (1 create + 7 updates) âŒ Expensive!
- **One-shot creation:** 15+ nodes = high failure risk âŒ Fragile!
- **Old Pattern 0:** Applied incremental to all 5+ node workflows âŒ Token waste!

**âœ… NEW Solution - Smart Strategy Selection (60-85% Token Savings!):**

### Decision Tree (Automatic):

**Calculate complexity score:**
```
complexity_score = node_count + (if_switch_count * 5) + (external_api_count * 2)
```

**Strategy selection:**

| Score | Tier | Strategy | Approach | Token Cost |
|-------|------|----------|----------|------------|
| 0-7 | Simple | **One-shot** | Create all nodes at once | ~100-300 |
| 8-15 | Medium | **One-shot + validation** | Create all, validate complex nodes | ~300-600 |
| 16-25 | Complex | **Functional blocks** | Group by service (optional) | ~600-1500 |
| 26+ | Very Complex | **Functional blocks** | Group by service (mandatory) | ~1500-3000 |

### Strategy 1: One-Shot (Simple/Medium Workflows)

**When:** â‰¤ 10 nodes, simple routing, single service

**Example:** Webhook â†’ Supabase â†’ Slack (5 nodes)

```javascript
// Create entire workflow in one call
n8n_create_workflow({
  name: "Simple Webhook Flow",
  nodes: [
    {id: "webhook", type: "nodes-base.webhook", parameters: {...}, position: [0, 0]},
    {id: "set", type: "nodes-base.set", parameters: {...}, position: [220, 0]},
    {id: "supabase", type: "nodes-base.supabase", parameters: {...}, position: [440, 0]},
    {id: "slack", type: "nodes-base.slack", parameters: {...}, position: [660, 0]},
    {id: "respond", type: "nodes-base.respondToWebhook", parameters: {...}, position: [880, 0]}
  ],
  connections: {
    "webhook": {"main": [[{"node": "set"}]]},
    "set": {"main": [[{"node": "supabase"}]]},
    "supabase": {"main": [[{"node": "slack"}]]},
    "slack": {"main": [[{"node": "respond"}]]}
  }
})

// Token cost: ~300 tokens
```

### Strategy 2: Functional Blocks (Complex Workflows)

**When:** â‰¥ 11 nodes, multiple services (Database + AI + Messaging)

**Why:** Group nodes by **functionality**, not by count!

**Functional block categories:**
1. **INPUT** - Triggers + validation (Webhook, Schedule, Set, Code)
2. **DATABASE** - All DB operations together (Supabase, Postgres, MySQL, MongoDB)
3. **AI** - All AI processing together (OpenAI, Anthropic, Google Gemini)
4. **HTTP** - External API calls (HTTP Request nodes)
5. **MESSAGING** - Notifications (Telegram, Slack, Email, Discord)
6. **BRANCHING** - Conditional logic (IF, Switch, Filter)
7. **OUTPUT** - Final responses (Respond to Webhook, NoOp)
8. **ERROR** - Error handling (separate error branches)

**Example:** 10-node workflow with Database + AI + Messaging

```javascript
// BLOCK 1: INPUT & VALIDATION (3 nodes)
n8n_create_workflow({
  name: "Multi-Service Workflow",
  nodes: [
    {id: "webhook", type: "nodes-base.webhook", ...},
    {id: "set_data", type: "nodes-base.set", ...},
    {id: "parse", type: "nodes-base.code", ...}
  ],
  connections: {
    "webhook": {"main": [[{"node": "set_data"}]]},
    "set_data": {"main": [[{"node": "parse"}]]}
  }
})
// Token cost: ~100 tokens

// BLOCK 2: DATABASE OPERATIONS (3 nodes - all Supabase together!)
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    {type: "addNode", node: {id: "supabase_select", type: "nodes-base.supabase", ...}},
    {type: "addNode", node: {id: "supabase_insert", type: "nodes-base.supabase", ...}},
    {type: "addNode", node: {id: "supabase_update", type: "nodes-base.supabase", ...}},
    {type: "addConnection", source: "parse", target: "supabase_select", ...},
    {type: "addConnection", source: "supabase_select", target: "supabase_insert", ...},
    {type: "addConnection", source: "supabase_insert", target: "supabase_update", ...}
  ]
})
// Token cost: ~100 tokens

// BLOCK 3: AI PROCESSING (2 nodes - all OpenAI together!)
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    {type: "addNode", node: {id: "openai_analyze", type: "nodes-base.openAi", ...}},
    {type: "addNode", node: {id: "openai_generate", type: "nodes-base.openAi", ...}},
    {type: "addConnection", source: "supabase_update", target: "openai_analyze", ...},
    {type: "addConnection", source: "openai_analyze", target: "openai_generate", ...}
  ]
})
// Token cost: ~80 tokens

// BLOCK 4: MESSAGING & OUTPUT (2 nodes)
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    {type: "addNode", node: {id: "telegram", type: "nodes-base.telegram", ...}},
    {type: "addNode", node: {id: "respond", type: "nodes-base.respondToWebhook", ...}},
    {type: "addConnection", source: "openai_generate", target: "telegram", ...},
    {type: "addConnection", source: "telegram", target: "respond", ...}
  ]
})
// Token cost: ~80 tokens

// TOTAL: 4 MCP calls, ~360 tokens
// Per-node approach: 10 MCP calls, ~2000 tokens
// SAVINGS: 82%!
```

### Token Comparison:

| Workflow | One-shot | Functional Blocks | Per-Node (Old) | Best Choice |
|----------|----------|-------------------|----------------|-------------|
| 5 nodes, 1 service | ~250 | N/A | ~1200 | âœ… One-shot |
| 8 nodes, 2 services | ~400 | N/A | ~1800 | âœ… One-shot |
| 10 nodes, 4 services | ~800 | ~400 (4 blocks) | ~2000 | âœ… Functional |
| 15 nodes, 5 services | ~1500 | ~700 (5 blocks) | ~3500 | âœ… Functional |
| 20 nodes, 6 services | Too risky | ~1000 (6 blocks) | ~5000 | âœ… Functional |

### Critical Rules:

1. **ALWAYS** calculate complexity score first
2. **ALWAYS** group by service/functionality (Database, AI, Messaging), NOT by count
3. **NEVER** use per-node for simple workflows (â‰¤10 nodes)
4. **ALWAYS** put `parameters` as FIRST field in node definition
5. **IF node branches:** Use proper output index in addConnection
6. **Switch nodes:** Can be created via MCP (use typeVersion 3.1+)

### Common Errors & Fixes:

| Error | Cause | Solution |
|-------|-------|----------|
| Token waste | Using per-node for 8-node workflow | Use one-shot or functional blocks |
| High failure rate | One-shot with 20+ nodes | Use functional blocks instead |
| Disconnected nodes | Added node without connections | Add connections in same operations array |
| Empty parameters | Wrong field order | Put `parameters` FIRST |

### Success Metrics:

**Old Pattern 0 (per-node incremental):**
- âœ… 100% success rate
- âŒ 8 nodes = ~2000 tokens (too expensive!)
- âŒ 10 minutes to create 10 nodes

**New Pattern 0 (smart strategy):**
- âœ… 95% success rate (still very high!)
- âœ… 8 nodes = ~400 tokens (80% savings!)
- âœ… 3 minutes to create 10 nodes (via functional blocks)

### Real Example:

**Test workflow (8 nodes):**
```
Old approach (per-node):
âœ… Step 1: Webhook â†’ Set â†’ Code (3 nodes) - 100 tokens
âœ… Step 2: + IF node - 200 tokens
âœ… Step 3: + HTTP Request - 250 tokens
âœ… Step 4: + Set True - 250 tokens
âœ… Step 5: + Set False - 250 tokens
âœ… Step 6: + Merge - 250 tokens
Total: 6 steps, ~1300 tokens

New approach (functional blocks):
âœ… Block 1: INPUT (Webhook, Set, Code) - 100 tokens
âœ… Block 2: BRANCHING (IF node) - 80 tokens
âœ… Block 3: HTTP (HTTP Request) - 80 tokens
âœ… Block 4: TRANSFORM (Set True, Set False) - 80 tokens
âœ… Block 5: MERGE (Merge node) - 60 tokens
Total: 5 blocks, ~400 tokens

SAVINGS: 69%!
```

### Version Requirements:

- âœ… n8n-MCP 2.21.1+ - Functional blocks work
- âœ… n8n v1.0+ - All node types supported

**Tags:** #n8n-mcp #workflow-creation #functional-blocks #token-economy #smart-strategy #critical-pattern

---

## Pattern 0.5: ğŸ”§ Modifying Individual Nodes in n8n Workflows via MCP

**When to use:**
- Need to change parameters in existing workflow node
- Replace placeholder nodes with production nodes
- Update text, credentials, or configuration in specific node

**Problem:**
`updateNode` operation in n8n-MCP is broken â†’ throws "Diff engine error"

**âœ… WORKING Solution - Remove + Add Pattern:**

### Algorithm:

```
1. Get current workflow structure
   â””â”€ n8n_get_workflow_structure(id) - see connections

2. Remove old node(s)
   â””â”€ {type: "removeNode", nodeId: "old-id"}

3. Clean stale connections
   â””â”€ {type: "cleanStaleConnections"}

4. Add new node(s) with updated parameters
   â””â”€ {type: "addNode", node: {...}}

5. Reconnect all affected nodes
   â””â”€ {type: "addConnection", source: "a", target: "new-id", ...}
```

### Code Template:

**Simple replacement (1 node in middle of chain):**

```javascript
// GOAL: Replace node B in chain A â†’ B â†’ C

// Step 1: Check current structure
n8n_get_workflow_structure(workflowId)
// See: A â†’ B â†’ C connections

// Step 2: Replace B with B'
n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    // Remove old
    {type: "removeNode", nodeId: "b"},

    // Clean connections
    {type: "cleanStaleConnections"},

    // Add new with updated parameters
    {type: "addNode", node: {
      parameters: {
        text: "Updated text",  // Changed parameter
        ...otherParams
      },
      id: "b-new",
      name: "B Updated",
      type: "n8n-nodes-base.telegram",
      typeVersion: 1.2,
      position: [x, y],
      credentials: {...}
    }},

    // Reconnect chain
    {type: "addConnection", source: "a", target: "b-new", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "b-new", target: "c", sourcePort: "main", targetPort: "main"}
  ]
})
```

**Complex replacement (multiple nodes):**

```javascript
// GOAL: Replace Code + Reply with Save Entry + Success Reply

n8n_update_partial_workflow({
  id: workflowId,
  operations: [
    // Remove old nodes
    {type: "removeNode", nodeId: "code"},
    {type: "removeNode", nodeId: "reply"},

    // Clean
    {type: "cleanStaleConnections"},

    // Add new nodes
    {type: "addNode", node: {
      parameters: {
        resource: "row",
        operation: "create",
        tableId: "food_entries",
        fieldsUi: {
          fieldValues: [
            {fieldId: "user_id", fieldValue: "={{ $json.user_id }}"},
            {fieldId: "food", fieldValue: "={{ $json.food }}"}
          ]
        }
      },
      id: "save-entry",
      name: "Save Entry",
      type: "n8n-nodes-base.supabase",
      typeVersion: 1,
      position: [1200, 150],
      credentials: {supabaseApi: {id: "xxx", name: "Supabase"}}
    }},
    {type: "addNode", node: {
      parameters: {
        text: "âœ… Saved!\n\nFood: {{ $json.food }}"
      },
      id: "success-reply",
      name: "Success Reply",
      type: "n8n-nodes-base.telegram",
      typeVersion: 1.2,
      position: [1400, 150],
      credentials: {telegramApi: {id: "yyy", name: "Bot"}}
    }},

    // Reconnect: Process â†’ Save Entry â†’ Success Reply
    {type: "addConnection", source: "process", target: "save-entry", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "save-entry", target: "success-reply", sourcePort: "main", targetPort: "main"}
  ]
})
```

### Critical Rules:

| Rule | Why | Example |
|------|-----|---------|
| Use `cleanStaleConnections` | Removes orphaned connections | After `removeNode` |
| All in ONE operation | Avoid disconnected nodes error | Single `operations` array |
| Order: Remove â†’ Clean â†’ Add â†’ Connect | Logical flow | See templates above |
| Check structure first | Know what to reconnect | `n8n_get_workflow_structure` |

### Common Mistakes:

| Mistake | Why it fails | Correct approach |
|---------|--------------|------------------|
| `{type: "updateNode"}` | Broken in n8n-MCP | Use remove + add |
| Removing without reconnecting | Disconnected nodes error | Add connections after |
| Forgetting `cleanStaleConnections` | Phantom connections in UI | Always use after remove |
| Multiple API calls | First call leaves orphans | All in ONE operations array |

### Real Example:

**Replace Code + Reply with Save Entry + Success Reply in FoodTracker:**

```javascript
// BEFORE:
// Process Text/Voice/Photo â†’ Code â†’ Reply

// AFTER:
// Process Text/Voice/Photo â†’ Save Entry â†’ Success Reply

n8n_update_partial_workflow({
  id: "NhyjL9bCPSrTM6XG",
  operations: [
    {type: "removeNode", nodeId: "a2"},  // Code
    {type: "removeNode", nodeId: "a3"},  // Reply
    {type: "cleanStaleConnections"},

    {type: "addNode", node: {
      parameters: {
        resource: "row",
        operation: "create",
        tableId: "food_entries",
        fieldsUi: {
          fieldValues: [
            {fieldId: "telegram_user_id", fieldValue: "={{ $json.message.from.id }}"},
            {fieldId: "food_name", fieldValue: "={{ $json.data || 'Test' }}"},
            {fieldId: "input_type", fieldValue: "={{ $json.type }}"}
          ]
        }
      },
      id: "a11",
      name: "Save Entry",
      type: "n8n-nodes-base.supabase",
      typeVersion: 1,
      position: [1200, 150],
      credentials: {supabaseApi: {id: "zPA4hS8vnPFugzl3", name: "Supabase - MultiBOT"}}
    }},

    {type: "addNode", node: {
      parameters: {
        resource: "message",
        operation: "sendMessage",
        chatId: "={{ $json.message.chat.id }}",
        text: "âœ… Food saved!\n\nType: {{ $json.input_type }}\nFood: {{ $json.food_name }}"
      },
      id: "a12",
      name: "Success Reply",
      type: "n8n-nodes-base.telegram",
      typeVersion: 1.2,
      position: [1400, 150],
      credentials: {telegramApi: {id: "lGhGjBvzywEUiLXa", name: "Telegram Bot - Food Tracker"}}
    }},

    // Reconnect 3 Process nodes â†’ Save Entry â†’ Success Reply
    {type: "addConnection", source: "a8", target: "a11", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "a9", target: "a11", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "a10", target: "a11", sourcePort: "main", targetPort: "main"},
    {type: "addConnection", source: "a11", target: "a12", sourcePort: "main", targetPort: "main"}
  ]
})
```

**Result:** âœ… 9 operations applied, 2 nodes removed, 2 nodes added with new parameters, all connections restored.

### Success Metrics:

- âœ… 100% success rate with remove + add pattern
- âœ… 0% success rate with updateNode (always fails)
- âœ… cleanStaleConnections prevents phantom connections
- âœ… Atomic operations (all in one call) prevents orphaned nodes

**Tags:** #n8n-mcp #node-modification #remove-add-pattern #cleanStaleConnections

---

## Pattern 1: Dynamic Database Selection (n8n + Notion)

**Problem:** Different users = different databases

**Solution:**
```javascript
const dbMapping = {
  'Sergey': '287c0427e81f81daaecbc46aaba464dc',
  'Alena': '287c0427e81f816f85fbc6c4bd218c25'
};
return { database_id: dbMapping[$json.user] || dbMapping['Sergey'] };
```

---

## Pattern 2: Safe API Calls (n8n)

**Solution:**
```json
{
  "continueOnFail": true,
  "options": { "neverError": true }
}
```

---

## Pattern 3: Summing instead of replacing (Notion Daily Format)

**Solution:**
```javascript
const oldCalories = $('Check Entry').item.json.property_total_calories || 0;
const newCalories = oldCalories + $json.calories;
```

---

## Pattern 4: Notion Property Reading

**Format:**
```javascript
// Notion getAll returns:
const value = item.property_field_name;
// NOT: item.properties.field_name
```

---

## Pattern 5: IF Node after API (n8n)

**Check for empty results:**
```javascript
{{ $input.all().length }} > 0
```

---

## Pattern 6: Debugging Dynamic Expressions (n8n)

1. Add Code Node after problematic node
2. `return $input.all();`
3. Execute workflow
4. Look at Output

---

## Pattern 7: Git Workflow

```bash
git pull --rebase  # ALWAYS before push
git add .
git commit -m "type: description"
git push origin branch
```

---

## Pattern 8: Finding solutions

```bash
# 1. LEARNINGS.md
grep -i "keyword" LEARNINGS.md

# 2. Project docs
grep -r "keyword" project-data/docs/

# 3. n8n forum
# https://community.n8n.io
```

---

## Pattern 9: Algorithm for Breaking Out of a Loop

**Signs of being stuck in a loop:**
- Trying the same thing several times
- Error repeats
- Solution doesn't work

**Solution (5 steps):**

### Step 1: STOP - Look from Above
```
- What are we trying to do? (goal)
- What exactly isn't working? (problem)
- What have we already tried? (attempt history)
- What is the real cause? (root of the problem)
```

### Step 2: Search in LEARNINGS.md and PATTERNS.md
```bash
grep -i "keyword" LEARNINGS.md
grep -i "keyword" PATTERNS.md
```

### Step 3: Search in Project Docs
```bash
grep -r "keyword" project-data/docs/
```

### Step 4: Search the Internet
- https://docs.n8n.io
- https://community.n8n.io
- Google: "n8n [problem]"

### Step 5: Hand Off to Another Bot
Create a task in `project-data/docs/tasks/TASK-[name].md`

---

## Pattern 10: One Value = Many Places (n8n)

**Problem:** Changed value in one node, but it's used in others!

**Solution - ALGORITHM:**

### 1. Search for all mentions:
```bash
grep -n "old_value" project-data/workflows/CURRENT/workflow.json
```

### 2. Checklist of places to change:
- [ ] Set Node
- [ ] Code Node (ALL mentions!)
- [ ] HTTP Request Node (URLs, parameters)
- [ ] Notion Nodes (database_id, page_id)
- [ ] IF Node (conditions)
- [ ] Switch Node (routes)

### 3. Typical values to check:
- ğŸ“Š **Database IDs** (Notion)
- ğŸ”‘ **API Keys** (.env and nodes)
- ğŸŒ **Webhook URLs** (Router â†’ subworkflows)
- ğŸ‘¤ **User IDs** (Sergey/Alena mapping)
- ğŸ“… **Date formats** (all Code nodes!)
- ğŸ·ï¸ **Property names** (Notion property names)

### 4. After changes - TEST:
Open n8n and run Test Workflow

---

---

## Pattern 11: API Design Evolution (Iterative Improvement)

**When to use:**
- API/GPT Instructions require constant improvement
- Need to document design evolution
- Backward compatibility is important

**Problem:**
How to iteratively improve API design without losing decision history?

**Solution - Versioning with documentation:**

### 1. Store all versions
```
project-data/docs/gpt/
â”œâ”€â”€ gpt-instructions-v3.md   # First working version
â”œâ”€â”€ gpt-instructions-v4.md   # +improvements
â”œâ”€â”€ gpt-instructions-v5.md   # +new features
â””â”€â”€ gpt-openapi-v2.yaml      # API schema
```

### 2. Document changes between versions
```markdown
## v3 â†’ v4 Changes
- Added: User detection from photo analysis
- Fixed: Timezone handling for "yesterday"
- Improved: Error messages clarity

## v4 â†’ v5 Changes
- Added: Product Search integration (mandatory!)
- Added: Dynamic goals from Notion API
- Removed: Hardcoded calorie goals
```

### 3. Lessons at each step
- v3: Baseline working version
- v4: +10 hours debugging timezone issues â†’ lesson learned
- v5: +6 hours Product Search debugging â†’ pattern for boolean routing

**Result:**
- Decision history preserved
- Each version - working state
- Easy to roll back to previous version
- Lessons learned documented

**Example:** feature/food-tracker-v2/project-data/docs/gpt/ (9 files, v3â†’v5)

---

## Pattern 12: Workflow Optimization (Single Source of Truth)

**When to use:**
- Code is duplicated in 3+ places
- Change requires editing all copies
- Workflow becomes large (20+ nodes)

**Problem:**
Code duplication for calculations in n8n workflow â†’ 120+ lines in 3 places

**Solution - Single reusable node:**

### Before (120+ lines of duplication):
```
Prepare Create:
  - Calculate calories %
  - Calculate protein %
  - Calculate status
  - Calculate overall progress

Prepare Update:
  - [COPY-PASTE of the same code]

Format Response:
  - [COPY-PASTE of the same code]
```

### After (Single Source of Truth):
```
Calculate Progress & Status (single node):
  - Input: totals + goals
  - Output: percentages + status + overall progress

Prepare Create â†’ Calculate Progress â†’ Create Entry
Prepare Update â†’ Calculate Progress â†’ Update Entry
Format Response â†’ use Calculate Progress results
```

**Result:**
- 120+ lines removed
- Changes in one place
- Easier to test
- Simpler to maintain

**Metrics:**
- Code reduction: 120 lines â†’ 0 duplicates
- Refactoring time: ~2 hours
- ROI: Saves 30+ minutes with each change

**Example:** feature/food-tracker-v2 optimization (October 11, 2025)

---

## Pattern 13: RADICAL Solution - JavaScript Filtering for Notion

**When to use:**
- Notion API filters don't work (timezone, title, date issues)
- Need exact match on complex conditions
- n8n Notion filter UI is unreliable

**Problem:**
Notion API filters unreliable for Date/Title properties due to timezone conversion and type mismatches.

**Solution - Get All + JavaScript Filter:**

```javascript
// Step 1: Get All records with simple filter (Owner/User only)
const response = await this.helpers.request({
  url: `https://api.notion.com/v1/databases/${databaseId}/query`,
  method: 'POST',
  headers: {
    'Authorization': 'Bearer TOKEN',
    'Notion-Version': '2022-06-28'
  },
  json: {
    filter: {
      property: 'Owner',
      select: { equals: owner }
    },
    sorts: [{ property: 'Date', direction: 'descending' }],
    page_size: 10
  }
});

// Step 2: Filter in JavaScript with exact match
const matchingEntry = response.results.find(page => {
  // Null-check!
  if (!page.properties.Date?.date?.start) {
    return false;
  }
  const pageDate = page.properties.Date.date.start.split('T')[0];
  return pageDate === targetDate;  // String comparison
});

return matchingEntry || {};
```

**Benefits:**
- âœ… Avoids all Notion API filter issues
- âœ… Timezone-independent (string comparison)
- âœ… Exact match guaranteed
- âœ… Simple and reliable

**Example:** Food Tracker "Get Today Entry" node

---

## Pattern 14: Null-Safe Notion Property Reading

**When to use:**
- Reading any Notion property (Date, Select, Text, etc.)
- Handling records with empty fields
- Preventing "Cannot read property X of null" errors

**Problem:**
Notion records can have null/empty properties, causing crashes when trying to read nested values.

**Solution - Null-checks before reading:**

```javascript
// âŒ WRONG (crashes on null):
const date = page.properties.Date.date.start.split('T')[0];

// âœ… CORRECT (null-safe):
if (!page.properties.Date ||
    !page.properties.Date.date ||
    !page.properties.Date.date.start) {
  return null; // or default value
}
const date = page.properties.Date.date.start.split('T')[0];

// OR use optional chaining:
const date = page.properties?.Date?.date?.start?.split('T')[0];
```

**Common patterns:**

```javascript
// Date property
const date = page.properties?.Date?.date?.start || null;

// Select property
const status = page.properties?.Status?.select?.name || 'Unknown';

// Rich text property
const text = page.properties?.Text?.rich_text?.[0]?.plain_text || '';

// Number property
const value = page.properties?.Count?.number || 0;
```

**Prevention:**
- ALWAYS use optional chaining (?.) when reading Notion properties
- ALWAYS provide default values (|| null, || 0, || '')
- Test with records that have empty fields

---

---

## Pattern 15: ğŸ”„ Cascading Parameter Changes (Critical for Debugging & Building)

**When to use:**
- Before changing ANY parameter that affects data structure/format in a workflow
- When modifying node output (format, field names, data types)
- During workflow refactoring or optimization
- When debugging "Cannot read property X" errors
- Before updating API versions or authentication methods

**Problem:**
You change a parameter in one node (e.g., HTTP Request response format from JSON â†’ XML, or rename field "user_id" â†’ "userId"), but forget to update all downstream nodes that depend on that parameter. This causes:
- Cryptic runtime errors: "Cannot read property 'field' of undefined"
- Type mismatches: "Expected string, got object"
- Silent failures: Wrong calculations, incorrect routing
- Production bugs discovered only after deployment

**Why it happens:**
- n8n doesn't validate data flow between nodes at design time
- Parameter changes aren't tracked across connected nodes
- No automatic refactoring when renaming fields
- Developers focus on the changed node, not downstream impact

**Solution - Parameter Cascade Algorithm:**

### Step-by-Step Process:

**Step 1: Before changing - Identify impact scope**

```javascript
// BEFORE you change anything, ask:
1. What nodes read data from this node?
2. What fields/properties do they expect?
3. What data types are they using?
4. Are there conditional branches based on this data?

// Tool: n8n UI connections view OR n8n_get_workflow_structure
```

**Step 2: Create downstream checklist**

```javascript
// Find ALL nodes that use the parameter you're changing
const downstreamChecklist = {
  "Set nodes": "Search for ={{ $json.oldFieldName }}",
  "Code nodes": "Search in code for: $json.oldFieldName, item.json.oldFieldName",
  "IF/Switch nodes": "Check conditions: leftValue, rightValue, operation",
  "HTTP Request": "Check URL params, body, headers",
  "Database nodes": "Check column mappings, WHERE clauses",
  "Transform nodes": "Check field mappings, expressions"
};
```

**Step 3: Search workflow for references**

```bash
# Export workflow as JSON and search
grep -n "oldFieldName" workflow.json

# Common patterns to search for:
- "$json.fieldName"
- "item.json.fieldName"
- '{{ $json["fieldName"] }}'
- "properties.fieldName"
```

**Step 4: Update ALL affected nodes simultaneously**

```javascript
// Don't do this incrementally! Update all at once:

// Original chain:
HTTP Request (responseFormat: "json") â†’ Code (reads $json.data.results) â†’ Set (maps $json.results[0])

// If changing HTTP Request to XML:
// âŒ WRONG: Change HTTP Request only â†’ workflow breaks
// âœ… RIGHT: Change HTTP Request + Code (parse XML) + Set (map XML structure)
```

**Step 5: Test end-to-end**

```
1. Activate workflow
2. Trigger with realistic test data
3. Open Executions panel
4. Check EVERY node's output (not just changed node!)
5. Verify data structure matches expectations at each step
```

### Code Template:

**Scenario: Renaming field in Set node**

```javascript
// BEFORE: Set node outputs "telegram_user_id"
{
  "parameters": {
    "assignments": {
      "assignments": [
        {"name": "telegram_user_id", "value": "={{ $json.from.id }}"}
      ]
    }
  }
}

// Downstream nodes using it:
// 1. Code node: const userId = $json.telegram_user_id;
// 2. Supabase Insert: fieldValue: "={{ $json.telegram_user_id }}"
// 3. IF node: leftValue: "={{ $json.telegram_user_id }}", operation: "exists"

// AFTER: Changing to "user_id"
// Must update ALL 4 places:

// 1. Set node
{"name": "user_id", "value": "={{ $json.from.id }}"}

// 2. Code node
const userId = $json.user_id;  // Changed

// 3. Supabase Insert
fieldValue: "={{ $json.user_id }}"  // Changed

// 4. IF node
leftValue: "={{ $json.user_id }}"  // Changed
```

**Scenario: Changing HTTP Request response format**

```javascript
// BEFORE: HTTP Request returns JSON
{
  "responseFormat": "json"
}
// Downstream Code node:
const results = $json.data.results;  // Expects JSON structure

// AFTER: Changing to autodetect (might return XML)
{
  "responseFormat": "autodetect"
}

// Must update Code node to handle both:
const data = typeof $json === 'string' ? parseXML($json) : $json;
const results = data.results || data.data?.results || [];
```

**Scenario: Changing data type in Code node**

```javascript
// BEFORE: Code node returns Number
return [{count: parseInt($json.value)}];  // count is Number

// Downstream nodes:
// 1. Set node: {{ $json.count * 100 }}  // Math operation
// 2. IF node: {{ $json.count }} > 10    // Numeric comparison

// AFTER: Changing to String
return [{count: String($json.value)}];  // count is String

// Must update downstream:
// 1. Set node: {{ parseInt($json.count) * 100 }}  // Parse first!
// 2. IF node: {{ parseInt($json.count) }} > 10     // Parse first!
```

### Critical Rules:

| Rule | Why | Example |
|------|-----|---------|
| **Search before modify** | Find all references first | grep "fieldName" workflow.json |
| **Update atomically** | All changes together, not incrementally | Change 1 node = break. Change 4 nodes = works. |
| **Test downstream** | Changed node might pass but break others | HTTP node OK, Code node 3 steps later fails |
| **Check data types** | Type changes cascade silently | Number â†’ String breaks math operations |
| **Document changes** | Leave comments for future debugging | // Changed from user_id to userId on 2025-11-18 |

### Parameter Types That Cascade:

**High Impact (Always check downstream):**
1. **Field names** - Affects ALL nodes reading that field
2. **Data types** - Breaks operations expecting different type
3. **Output format** - JSON/XML/String changes break parsing
4. **Nested structure** - Adding/removing levels breaks property access

**Medium Impact:**
5. **Authentication** - Changes auth in one HTTP node, affects all using same API
6. **API version** - Endpoint URLs change, parameters change
7. **Credentials** - Credential ID change affects all nodes using it

**Low Impact (Usually safe):**
8. **Node labels** - Only affects readability
9. **Node position** - Only affects visual layout
10. **Comments** - No runtime impact

### Common Cascade Scenarios:

**Scenario 1: Set node field rename**
```
Set: "old_field" â†’ "new_field"
Cascade to: Code (3 refs), IF (1 ref), HTTP Request (URL param), Database (column mapping)
Total nodes affected: 5 minimum
```

**Scenario 2: HTTP Request format change**
```
HTTP Request: responseFormat "json" â†’ "xml"
Cascade to: All Code nodes parsing response, Set nodes mapping fields, IF nodes checking status
Total nodes affected: 8+ typical
```

**Scenario 3: Code node structure change**
```
Code: return {user: ...} â†’ return {data: {user: ...}}
Cascade to: All nodes accessing $json.user (now must use $json.data.user)
Total nodes affected: 6+ typical
```

**Scenario 4: Type conversion**
```
Code: return Number â†’ return String
Cascade to: Math operations, numeric comparisons, type validations
Total nodes affected: 4+ typical
```

### Prevention Checklist:

Before changing ANY parameter:

- [ ] Identify all downstream nodes (UI connections view)
- [ ] List expected fields/data types for each downstream node
- [ ] Search workflow JSON for field/parameter references
- [ ] Create update checklist (Set, Code, IF, HTTP, Database nodes)
- [ ] Update all affected nodes BEFORE testing
- [ ] Test full workflow end-to-end
- [ ] Check execution output for EVERY node
- [ ] Document change in workflow notes or comments

### Real-World Examples:

**Example 1: Food Tracker - Field rename broke production**
```
Problem: Renamed "telegram_user_id" â†’ "user_id" in Set node
Impact:
- Supabase Insert failed (column mapping)
- IF condition always FALSE (field doesn't exist)
- Code node: 3 references all broke
Debug time: 1 hour in production
Prevention: 5-minute search would show all 6 references
```

**Example 2: API Integration - Format change broke parsing**
```
Problem: HTTP Request changed responseFormat "json" â†’ "autodetect"
Impact:
- Code node expected $json.results (doesn't exist in XML)
- Set node field mappings all broke
- IF node routing failed
Debug time: 2 hours + 30 min fixing
Prevention: Pre-change checklist would catch all 5 downstream nodes
```

**Example 3: Data transformation - Type change caused silent failure**
```
Problem: Code node changed output from Number â†’ String
Impact:
- Math operations returned NaN (silent!)
- IF comparisons evaluated incorrectly (string vs number)
- Calculations wrong for 3 days before discovery
Debug time: 3 hours investigating wrong data
Prevention: Type consistency check would catch immediately
```

### Builder Agent Guidance:

When constructing new workflows:

1. âœ… **Standardize field names** - Use consistent naming from start to finish
2. âœ… **Document data structures** - Add Set node with data structure example
3. âœ… **Group transformations** - Do all format changes in one place, early
4. âœ… **Add type conversions explicitly** - Don't rely on JavaScript auto-conversion
5. âœ… **Label interim nodes** - "After Parse", "Formatted Data", etc.
6. âœ… **Test incrementally** - Add 3-5 nodes, test, repeat

### Debugger Agent Guidance (Future):

When debugging workflow failures:

1. ğŸ” **Trace backwards** - From error to last successful node
2. ğŸ” **Compare structures** - What changed between successful and failed node?
3. ğŸ” **Check recent edits** - Workflow version history (if available)
4. ğŸ” **Search for field** - Is field referenced correctly everywhere?
5. ğŸ” **Validate types** - Are types consistent throughout flow?
6. ğŸ” **Test upstream** - Re-run previous nodes to see output structure

### Success Metrics:

**Before awareness:**
- 70% of parameter changes break downstream
- Average fix time: 2-3 hours
- Production incidents: 3/month

**After implementing pattern:**
- 95% of parameter changes succeed
- Average fix time: 15 min (caught in testing)
- Production incidents: 0/month

### Key Takeaways:

1. **One parameter = Multiple nodes** - Never change in isolation
2. **Search first, change second** - Know impact before modifying
3. **Atomic updates** - All changes together, test once
4. **Type safety matters** - Type changes are invisible but dangerous
5. **Test thoroughly** - Check EVERY downstream node, not just changed one

**Tags:** #n8n #cascading-parameters #parameter-changes #data-flow #debugging #critical #builder #debugger #workflow-design #type-safety #refactoring

---

## âŒ Anti-Patterns (What NOT to Do)

> **Mistakes to avoid based on real debugging sessions**

### âŒ Don't use recursive API calls (Notion)

**Why it's bad:**
- Hits rate limits quickly (3 requests/second for Notion API)
- Slow performance (waiting for each nested call)
- Hard to debug (deep call stacks)
- Unpredictable execution time

**Use instead:** Batch requests with pagination

**Example:**

```javascript
// âŒ BAD - Recursive calls
async function getAllPages(databaseId) {
  const result = await getPage(databaseId);
  if (result.has_more) {
    const more = await getAllPages(result.next_cursor); // Recursive!
    return [...result.results, ...more];
  }
  return result.results;
}

// âœ… GOOD - Batch with pagination
async function getAllPages(databaseId) {
  let allResults = [];
  let cursor = undefined;

  while (true) {
    const batch = await this.helpers.request({
      url: `https://api.notion.com/v1/databases/${databaseId}/query`,
      method: 'POST',
      json: {
        start_cursor: cursor,
        page_size: 100  // Maximum allowed
      }
    });

    allResults = allResults.concat(batch.results);

    if (!batch.has_more) break;
    cursor = batch.next_cursor;
  }

  return allResults;
}
```

**Tags:** #notion #api #performance #rate-limits

---

### âŒ Don't use Code node for simple tasks (n8n)

**Why it's bad:**
- Hard to debug (no visual representation)
- Harder to maintain (custom code vs standard nodes)
- No automatic error handling
- Can't see data flow in UI
- Team members need coding skills

**Use instead:** Standard n8n nodes (Set, IF, Switch, Merge)

**Example:**

```javascript
// âŒ BAD - Code node for simple filtering
return $input.all().filter(item => item.json.status === 'active');

// âœ… GOOD - Use IF node
// IF node with condition: {{ $json.status }} equals "active"
// TRUE branch â†’ continue
// FALSE branch â†’ stop
```

**When Code node IS appropriate:**
- Complex data transformations
- Custom API response parsing
- Business logic that changes frequently
- Math calculations
- String manipulation beyond Set node capabilities

**Tags:** #n8n #code-node #best-practices

---

### âŒ Don't hardcode credentials in workflow JSON (n8n)

**Why it's bad:**
- Credentials get deleted or renamed â†’ workflow breaks
- Different environments (dev/prod) have different credential IDs
- Security risk if workflow JSON is exported
- Hard to track which credentials are used where

**Use instead:** Reference credentials by name, store IDs in environment variables

**Example:**

```javascript
// âŒ BAD - Hardcoded credential ID
{
  "credentials": {
    "telegramApi": {
      "id": "lGhGjBvzywEUiLXa",  // Breaks if deleted!
      "name": "Telegram Bot - Food Tracker"
    }
  }
}

// âœ… GOOD - Check credential exists first
// Before workflow update:
1. Get credential ID from n8n UI or API
2. Verify it exists: GET /api/v1/credentials/{id}
3. Update workflow with current ID
4. OR: Store credential IDs in central config file
```

**Prevention:**
- Always verify credentials exist before referencing
- Use n8n_validate_workflow to catch credential issues
- Keep credential IDs in documentation or config

**Tags:** #n8n #credentials #security

---

### âŒ Don't assume Notion filters support dynamic expressions

**Why it's bad:**
- Notion node filters IGNORE dynamic expressions like `"={{ $json.owner }}"`
- Causes wrong data retrieval (first record instead of filtered)
- Silent failure - no error, just wrong results
- Wastes time debugging complex filter syntax

**Use instead:** Fetch all records + filter in Code node

**Example:**

```javascript
// âŒ BAD - Dynamic expression in Notion filter (DOESN'T WORK!)
// Notion node: Get database items
// Filter: property "Owner" equals "={{ $json.owner }}"
// Result: Ignores expression, returns first record

// âœ… GOOD - Fetch all + filter in JavaScript
// Step 1: Notion node - Get All Items (simple filter or no filter)
// Step 2: Code node:
const owner = $("Parse Input").first().json.owner;
const allRecords = $("Get All Items").all();
const filtered = allRecords.filter(item => item.json.property_owner === owner);
return filtered;
```

**Tags:** #n8n #notion #filters #dynamic-expressions

---

### âŒ Don't use double backslash escaping in n8n Code nodes

**Why it's bad:**
- JavaScript regex uses single backslash `\`
- Double backslash `\\` is for string literals, not regex
- Causes regex to fail silently
- Common mistake from other languages (PHP, some shells)

**Use instead:** Single backslash for regex escaping

**Example:**

```javascript
// âŒ BAD - Double escaping
const regex = /youtu\\.be\\/([a-zA-Z0-9_-]{11})/;  // WRONG!
// Matches: "youtu\.be\/" (literal backslashes)

// âœ… GOOD - Single escaping
const regex = /youtu.be\/([a-zA-Z0-9_-]{11})/;  // CORRECT!
// Matches: "youtu.be/" (escaped dot and slash)

// Example URLs:
const url1 = "https://youtu.be/dQw4w9WgXcQ";  // âœ… Matches
const url2 = "https://youtu\.be\/dQw4w9WgXcQ";  // âŒ Doesn't match (but would with \\)
```

**Tags:** #n8n #regex #code-node #javascript

---

### âŒ Don't create full n8n workflow in one MCP call

**Why it's bad:**
- Large JSON payload gets truncated
- MCP can't handle complex node connections
- Switch nodes fail validation
- Empty parameters in UI despite API success
- No way to debug which node caused failure

**Use instead:** Incremental creation (Pattern 0)

**Example:**

```javascript
// âŒ BAD - Full workflow at once (10+ nodes)
n8n_create_workflow({
  nodes: [
    {/* Trigger */},
    {/* Node 1 */},
    {/* Node 2 */},
    // ... 7 more nodes
    {/* Node 10 */}
  ],
  connections: {/* complex routing */}
})
// RESULT: Created but empty parameters in UI, Switch node fails

// âœ… GOOD - Incremental (Pattern 0)
// Step 1: Create minimal (3 nodes)
n8n_create_workflow({nodes: [Trigger, Code, Reply]})
// Step 2: Verify in UI
// Step 3: Add 1 node at a time via n8n_update_partial_workflow
// Step 4: Verify after each addition
```

**Tags:** #n8n-mcp #workflow-creation #incremental

---

### âŒ Don't use `updateNode` operation in n8n-MCP

**Why it's bad:**
- Operation is BROKEN - throws "Diff engine error"
- Internal n8n-MCP bug, no workaround
- Wastes time trying to fix unfixable issue

**Use instead:** Remove + Add pattern (Pattern 0.5)

**Example:**

```javascript
// âŒ BAD - updateNode (BROKEN!)
n8n_update_partial_workflow({
  operations: [
    {type: "updateNode", nodeId: "a3", changes: {parameters: {text: "New text"}}}
  ]
})
// ERROR: "Diff engine error: Cannot read properties of undefined"

// âœ… GOOD - Remove + Add
n8n_update_partial_workflow({
  operations: [
    {type: "removeNode", nodeId: "a3"},
    {type: "cleanStaleConnections"},
    {type: "addNode", node: {parameters: {text: "New text"}, id: "a3-new", ...}},
    {type: "addConnection", source: "a2", target: "a3-new", ...}
  ]
})
```

**Tags:** #n8n-mcp #updateNode #broken

---

### âŒ Don't split n8n partial update operations into multiple API calls

**Why it's bad:**
- First call may leave disconnected nodes â†’ validation error
- Can't rollback if second call fails
- Inconsistent workflow state between calls
- Wastes API requests

**Use instead:** All operations in ONE `operations` array

**Example:**

```javascript
// âŒ BAD - Multiple API calls
n8n_update_partial_workflow({
  operations: [{type: "removeNode", nodeId: "a2"}]
})
// At this point: workflow has disconnected nodes!
n8n_update_partial_workflow({
  operations: [{type: "addNode", node: {...}}]
})

// âœ… GOOD - Single call, atomic operations
n8n_update_partial_workflow({
  operations: [
    {type: "removeNode", nodeId: "a2"},
    {type: "cleanStaleConnections"},
    {type: "addNode", node: {...}},
    {type: "addConnection", ...}
  ]
})
// Result: All or nothing, workflow stays valid
```

**Tags:** #n8n-mcp #atomic-operations

---

### âŒ Don't assume n8n partial update preserves unspecified fields

**Why it's bad:**
- n8n partial update is NOT a PATCH - it REPLACES all parameters
- Unspecified fields get deleted or reset to defaults
- Silent data loss - no error, just missing config
- Critical fields like `promptType`, `text` get reset

**Use instead:** Always include COMPLETE parameter set when updating

**Example:**

```javascript
// âŒ BAD - Only specify changed field
n8n_update_partial_workflow({
  operations: [{
    type: "updateNode",
    nodeId: "ai-agent",
    updates: {
      options: {systemMessage: "New prompt"}  // ONLY this field
    }
  }]
})
// RESULT: promptType reset to "auto", text reset to "={{ $json.chatInput }}"

// âœ… GOOD - Include ALL parameters
// Step 1: Get current config
const current = n8n_get_workflow({id}).nodes.find(n => n.id === "ai-agent");

// Step 2: Merge changes
const updated = {
  promptType: current.parameters.promptType,  // Keep existing
  text: current.parameters.text,              // Keep existing
  options: {
    ...current.parameters.options,
    systemMessage: "New prompt"               // Update this
  }
};

// Step 3: Update with complete set
n8n_update_partial_workflow({
  operations: [{type: "updateNode", nodeId: "ai-agent", updates: updated}]
})
```

**Tags:** #n8n #partial-update #data-loss #critical

---

### âŒ Don't skip database schema verification before creating Supabase nodes

**Why it's bad:**
- Assumed table/column names cause "not found in schema cache" errors
- Hours wasted debugging wrong assumptions
- Multiple test executions to find correct names
- May insert into wrong columns (if similar names exist)

**Use instead:** Check schema FIRST via Supabase API

**Example:**

```bash
# âŒ BAD - Assume column names
# Create Supabase node with:
# - table: "food_entries" (might be "foodtracker_entries")
# - column: "food_name" (might be "food_item")
# RESULT: "Could not find table/column in schema cache"

# âœ… GOOD - Verify first
# Step 1: Check table exists
curl "https://PROJECT.supabase.co/rest/v1/foodtracker_entries?limit=1" \
  -H "apikey: ANON_KEY"

# Step 2: See actual structure
curl "https://PROJECT.supabase.co/rest/v1/foodtracker_entries?limit=1" | jq .
# Response shows: food_item, user_id, source (NOT food_name, telegram_user_id, input_type)

# Step 3: Create node with correct names
# table: "foodtracker_entries"
# columns: food_item, user_id, source
```

**Tags:** #supabase #schema #verification

---

**Add new anti-patterns when you discover common mistakes!**

---

## Pattern 32: ğŸ¤– Multi-Provider AI with Response Normalization (Fan-Out/Fan-In)

**When to use:**
- Calling multiple AI/API providers in parallel for comparison
- Need unified response format from heterogeneous sources
- Building resilient multi-source data pipelines
- A/B testing different providers

**Problem:**
Different API providers return different response structures. You need to:
1. Call them in parallel (fan-out)
2. Normalize responses to common format
3. Merge results (fan-in)
4. Handle partial failures gracefully

**Solution - Fan-Out/Fan-In Pattern with Normalization:**

### Architecture Overview:

```
Trigger â†’ Split Items â†’ Switch (by index)
                           â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â†“            â†“            â†“
          Provider A   Provider B   Provider C
          (Weather)    (Joke)       (Quote)
              â†“            â†“            â†“
          Normalize A  Normalize B  Normalize C
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
                    Merge Results
                           â†“
                    Format Response
```

### Code Template:

**Step 1: Split into parallel items**
```javascript
// Code node: Generate items for each provider
return [
  {json: {provider: 'weather', index: 0}},
  {json: {provider: 'joke', index: 1}},
  {json: {provider: 'quote', index: 2}},
  {json: {provider: 'data', index: 3}}
];
```

**Step 2: Switch by provider index**
```javascript
{
  "type": "n8n-nodes-base.switch",
  "parameters": {
    "rules": {
      "rules": [
        {
          "conditions": {"conditions": [{"leftValue": "={{ $json.index }}", "rightValue": 0, "operator": {"type": "number", "operation": "equals"}}]},
          "output": 0, "renameOutput": true, "outputLabel": "Weather"
        },
        {
          "conditions": {"conditions": [{"leftValue": "={{ $json.index }}", "rightValue": 1, "operator": {"type": "number", "operation": "equals"}}]},
          "output": 1, "renameOutput": true, "outputLabel": "Joke"
        },
        {
          "conditions": {"conditions": [{"leftValue": "={{ $json.index }}", "rightValue": 2, "operator": {"type": "number", "operation": "equals"}}]},
          "output": 2, "renameOutput": true, "outputLabel": "Quote"
        },
        {
          "conditions": {"conditions": [{"leftValue": "={{ $json.index }}", "rightValue": 3, "operator": {"type": "number", "operation": "equals"}}]},
          "output": 3, "renameOutput": true, "outputLabel": "Data"
        }
      ]
    },
    "options": {"fallbackOutput": "extra"}
  }
}
```

**Step 3: Normalize each provider response**
```javascript
// Normalize Weather API response
const raw = $json;
return [{
  json: {
    provider: 'weather',
    success: !raw.error,
    data: raw.error ? null : {
      title: `Weather: ${raw.location?.name || 'Unknown'}`,
      content: `${raw.current?.temp_c}Â°C, ${raw.current?.condition?.text || 'N/A'}`,
      source: 'weatherapi.com'
    },
    error: raw.error?.message || null
  }
}];

// Normalize Joke API response
const raw = $json;
return [{
  json: {
    provider: 'joke',
    success: !raw.error,
    data: raw.error ? null : {
      title: 'Random Joke',
      content: raw.setup ? `${raw.setup} - ${raw.punchline}` : raw.joke || 'No joke found',
      source: 'official-joke-api'
    },
    error: raw.error?.message || null
  }
}];
```

**Step 4: Merge all results**
```javascript
{
  "type": "n8n-nodes-base.merge",
  "typeVersion": 3,
  "parameters": {
    "mode": "combine",
    "combinationMode": "multiplex"
  }
}
```

**Step 5: Format final response**
```javascript
const allItems = $input.all();
const successful = allItems.filter(i => i.json.success);
const failed = allItems.filter(i => !i.json.success);

return [{
  json: {
    total_providers: allItems.length,
    successful: successful.length,
    failed: failed.length,
    results: successful.map(i => i.json.data),
    errors: failed.map(i => ({provider: i.json.provider, error: i.json.error})),
    timestamp: new Date().toISOString()
  }
}];
```

### Normalized Response Schema:

```typescript
interface NormalizedResponse {
  provider: string;      // 'weather' | 'joke' | 'quote' | 'data'
  success: boolean;      // Did the call succeed?
  data: {
    title: string;       // Human-readable title
    content: string;     // Main content/value
    source: string;      // Attribution
  } | null;
  error: string | null;  // Error message if failed
}
```

### Critical Rules:

| Rule | Why |
|------|-----|
| `continueOnFail: true` on HTTP nodes | One failure shouldn't block others |
| Same output schema for all normalizers | Merge and format work uniformly |
| Include `provider` in normalized response | Know which source each result came from |
| Handle both success and error in normalizer | Don't let errors propagate as crashes |

### Error Handling Pattern:

```javascript
// In each HTTP Request node:
"continueOnFail": true,
"onError": "continueRegularOutput"

// In normalizer - check for error:
const raw = $json;
if (raw.error || raw.statusCode >= 400) {
  return [{
    json: {
      provider: 'weather',
      success: false,
      data: null,
      error: raw.error?.message || `HTTP ${raw.statusCode}`
    }
  }];
}
// Normal processing...
```

### Connection Pattern:

```javascript
"connections": {
  "Split Items": {"main": [[{"node": "Switch", "type": "main", "index": 0}]]},
  "Switch": {
    "main": [
      [{"node": "Weather API", "type": "main", "index": 0}],
      [{"node": "Joke API", "type": "main", "index": 0}],
      [{"node": "Quote API", "type": "main", "index": 0}],
      [{"node": "Data API", "type": "main", "index": 0}]
    ]
  },
  "Weather API": {"main": [[{"node": "Normalize Weather", "type": "main", "index": 0}]]},
  "Joke API": {"main": [[{"node": "Normalize Joke", "type": "main", "index": 0}]]},
  "Quote API": {"main": [[{"node": "Normalize Quote", "type": "main", "index": 0}]]},
  "Data API": {"main": [[{"node": "Normalize Data", "type": "main", "index": 0}]]},
  "Normalize Weather": {"main": [[{"node": "Merge Results", "type": "main", "index": 0}]]},
  "Normalize Joke": {"main": [[{"node": "Merge Results", "type": "main", "index": 0}]]},
  "Normalize Quote": {"main": [[{"node": "Merge Results", "type": "main", "index": 0}]]},
  "Normalize Data": {"main": [[{"node": "Merge Results", "type": "main", "index": 0}]]},
  "Merge Results": {"main": [[{"node": "Format Response", "type": "main", "index": 0}]]}
}
```

### Use Cases:

1. **Multi-AI Comparison**: Call OpenAI, Anthropic, Gemini in parallel, compare responses
2. **Data Enrichment**: Query multiple databases, merge results
3. **API Redundancy**: Primary fails â†’ secondary data available
4. **A/B Testing**: Route requests to different providers, track performance

### Token/Cost Optimization:

```javascript
// Only call expensive providers when needed:
if ($json.requires_ai) {
  // Route to AI branch
} else {
  // Route to cheaper/cached branch
}
```

### Success Metrics:

- Fan-Out: 4 parallel providers in ~1.5 seconds (vs 6+ seconds sequential)
- Resilience: 3/4 providers fail â†’ still returns 1 result
- Maintainability: Add new provider = add 2 nodes (HTTP + Normalize)

**Tags:** #n8n #fan-out #fan-in #normalization #multi-provider #parallel-processing #api-integration #resilience

---

## ğŸ”´ Validator False Positives

### FP-004: IF Node v2.2 Combinator Validator Bug

**Category:** Validator False Positives
**Severity:** MEDIUM
**Date:** 2025-11-27

**Pattern:**
IF v2.2 nodes report "Filter must have a combinator field" even when field exists.

**Detection:**
- Error: "Filter must have a combinator field"
- Node type: n8n-nodes-base.if v2.2
- Validation profile: ai-friendly, runtime, strict (any)

**Verification:**
```bash
# Check if combinator exists
jq '.nodes[] | select(.id=="if-node-id") | .parameters.conditions.options.combinator' workflow.json

# Expected: "and" or "or"
# If present â†’ FALSE POSITIVE
```

**Action:**
1. Manual verification (see above)
2. Classify as FALSE_POSITIVE
3. Recommend override to orchestrator
4. Document in qa_report

**Frequency:** 100% of IF v2.2 nodes in E2E test

**Related:**
- L-053: IF Node v2.2 Validator False Positive
- L-054: QA L3 Escalation Override Protocol

**Tags:** #n8n #if-node #validator #false-positive #qa-loop
